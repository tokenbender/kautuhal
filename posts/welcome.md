---
title: welcome
date: 2023-08-24
excerpt: my journey from intel to llm research and the models that defined my path
---

I'm TokenBender. I love working with large language models.

## Background

Formerly a Technical Lead at Intel India, I led high-impact projects in the server division and built methods to save significant capital and labour when we had a cap of 5% workforce in office during COVID lockdowns. I developed a deep interest in NLP and now focus on end-to-end LLM pipelines, including orchestration, dataset curation, filtering, reweighting, and multilingual alignment (Indic languages).

This is how my journey has been so far in the post-ChatGPT world.

## Key Achievements

**codeCherryPop**: Built from Llama 2 7B, the first useful small coder that gained significant attention.
[LinkedIn announcement](https://www.linkedin.com/posts/abhishek-harshvardhan-mishra_just-going-to-silently-drop-this-here-my)

**Chai AI Success**: Achieved Top 5 model ranking for multiple months in the Chai AI Character Roleplay hackathon with ~78%+ satisfaction rates.

**evolvedSeeker**: Upgraded the DeepSeek Coder 1.3B base to create what became the best-performing local model in the 1B range for coding tasks.
[Reddit discussion](https://www.reddit.com/r/LocalLLaMA/comments/181h3lv/13b_with_6829_humaneval_lol_dont_behead_me_part)

**PIC Series**: Secured a Top 10 spot on the open Hugging Face leaderboard with my PIC (Partner-in-Crime) series—demonstrating pioneering function-calling, character engagement, and generic performance boosts all in one model.
[Model on HuggingFace](https://huggingface.co/TokenBender/pic_7B_mistral_Full_v0.2)

**Multilingual Innovation**: Built the first model fine-tuned for both RAG and generic chat, also pioneered this approach in Indic language space.
[Navarna Model](https://huggingface.co/TokenBender/Navarna_v0_1_OpenHermes_Hindi)

## Current Work

My datasets and models have amassed several thousand downloads on Hugging Face, particularly in the coding category. Check out my profile: [TokenBender on HuggingFace](https://huggingface.co/TokenBender)

I spent the last several months diving into multimodal RAG (Retrieval-Augmented Generation) for structured/unstructured documents and structured extraction in Document Visual QA by fine-tuning specialized VLMs.

I microblog as "@tokenbender" on Twitter—constantly dissecting the latest developments, limits, and advantages of current systems.

## What to Expect

I'll be writing about:
- LLM research and practical insights
- Post-training techniques and methodologies
- Multimodal AI and document understanding
- Dataset curation and model alignment
- Thoughts on the evolving AI landscape